{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Prep ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data = np.array(data)\n",
    "m,n = data.shape\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# Split the data to train and test\n",
    "# Data is divided by 255 to normalize (range 0,1)\n",
    "train_data = data[:33600, 1:].transpose() / 255\n",
    "train_labels = data[:33600 ,0]\n",
    "train_m = 33600\n",
    "\n",
    "test_data = data[33601:, 1:].transpose() / 255\n",
    "test_labels = data[33601:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relu(matrix):\n",
    "    return np.maximum(matrix, 0)\n",
    "\n",
    "def Deriv_Relu(matrix):\n",
    "    return matrix > 0\n",
    "\n",
    "# This one causes errors\n",
    "# def Softmax(logits):\n",
    "#     exp_logits = np.exp(logits - np.max(logits, axis=1, keepdims=True))  # Numerical stability improvement\n",
    "#     return exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
    "\n",
    "def Softmax(logits):\n",
    "    logits = np.exp(logits) / sum(np.exp(logits))\n",
    "    return logits\n",
    "\n",
    "class Neural_Network:\n",
    "    def __init__(self, a0, labels):\n",
    "        # Weights and Biases\n",
    "        self.w1 = np.random.rand(10, 784) - 0.5\n",
    "        self.b1 = np.random.rand(10, 1) - 0.5\n",
    "        self.w2 = np.random.rand(10, 10) - 0.5\n",
    "        self.b2 = np.random.rand(10, 1) - 0.5\n",
    "        \n",
    "        # Others\n",
    "        self.a0 = a0\n",
    "        _,self.m = self.a0.shape\n",
    "        self.labels = labels\n",
    "        \n",
    "        # one-hot encode labels\n",
    "        self.y = np.zeros((self.labels.size, self.labels.max() + 1))\n",
    "        self.y[np.arange(self.labels.size), self.labels] = 1\n",
    "        self.y = self.y.T\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        # Hidden Layer\n",
    "        self.z1 = self.w1.dot(x) + self.b1\n",
    "        self.a1 = Relu(self.z1)\n",
    "        \n",
    "        # Output Layer\n",
    "        self.z2 = self.w2.dot(self.a1) + self.b2\n",
    "        self.a2 = Softmax(self.z2)\n",
    "        \n",
    "        return self.a2\n",
    "    \n",
    "    def calc_cost(self):\n",
    "        # Cost Function (Mean Square Error)\n",
    "        return np.sum(np.power((self.a2 - self.y), 2) / 2) / 784\n",
    "     \n",
    "    def backward_pass(self):\n",
    "        self.dZ2 = self.a2 - self.y\n",
    "        self.dW2 = 1 / self.m * self.dZ2.dot(self.a1.T)\n",
    "        \n",
    "        self.db2 = 1 / self.m * np.sum(self.dZ2)\n",
    "        \n",
    "        # We element wise multiply the derivative of Relu as Relu is an element-wise activation function\n",
    "        self.dZ1 = self.w2.T.dot(self.dZ2) * Deriv_Relu(self.z1)\n",
    "        self.dW1 = 1 / self.m * self.dZ1.dot(self.a0.T)\n",
    "        \n",
    "        self.db1 = 1 / self.m * np.sum(self.dZ1)\n",
    "        \n",
    "        return self.w1, self.w2, self.b1, self.b2\n",
    "        \n",
    "    def grad_descent(self, LR):\n",
    "        self.w1 -= LR * self.dW1\n",
    "        self.w2 -= LR * self.dW2\n",
    "        self.b1 -= LR * self.db1\n",
    "        self.b2 -= LR * self.db2\n",
    "        \n",
    "    def train(self, LR, epochs):\n",
    "        for i in range(epochs):\n",
    "            self.forward_pass(self.a0)\n",
    "            self.backward_pass()\n",
    "            self.grad_descent(LR)\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                print(\"Iteration: \", i)\n",
    "                print(self.get_accuracy(self.labels))\n",
    "                print()\n",
    "\n",
    "    def predict(self, t_data, t_labels):\n",
    "        index = randrange(t_data.shape[1])\n",
    "        current_image = t_data[:, index, None]\n",
    "        \n",
    "        prediction = self.forward_pass(t_data[:, index, None])\n",
    "        \n",
    "        label = t_labels[index]\n",
    "        \n",
    "        print(\"Label: \", label)\n",
    "        print(\"Prediction: \", prediction.argmax())\n",
    "        print(\"Confidence: \", prediction.max() * 100)\n",
    "        \n",
    "        current_image = current_image.reshape((28, 28)) * 255\n",
    "        plt.gray()\n",
    "        plt.imshow(current_image, interpolation='nearest')\n",
    "        plt.show()\n",
    "\n",
    "    def get_accuracy(self, labels):\n",
    "        predictions = np.argmax(self.a2, 0)\n",
    "        return np.sum(predictions == labels) / labels.size\n",
    "    \n",
    "    def load_model(self, w1, w2, b1, b2):\n",
    "        self.w1 = np.genfromtxt(w1)\n",
    "        self.w2 = np.genfromtxt(w2)\n",
    "        self.b1 = np.genfromtxt(b1)\n",
    "        self.b2 = np.genfromtxt(b2)\n",
    "    \n",
    "    def save_model(self):\n",
    "        np.savetxt(\"Model/w1.csv\", self.w1, delimiter=\",\")\n",
    "        np.savetxt(\"Model/w2.csv\", self.w2, delimiter=\",\")\n",
    "        np.savetxt(\"Model/b1.csv\", self.b1, delimiter=\",\")\n",
    "        np.savetxt(\"Model/b2.csv\", self.b2, delimiter=\",\")\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "0.13095238095238096\n",
      "\n",
      "Iteration:  10\n",
      "0.42345238095238097\n",
      "\n",
      "Iteration:  20\n",
      "0.6244345238095238\n",
      "\n",
      "Iteration:  30\n",
      "0.5685416666666666\n",
      "\n",
      "Iteration:  40\n",
      "0.7492857142857143\n",
      "\n",
      "Iteration:  50\n",
      "0.7536309523809523\n",
      "\n",
      "Iteration:  60\n",
      "0.7675297619047619\n",
      "\n",
      "Iteration:  70\n",
      "0.8040178571428571\n",
      "\n",
      "Iteration:  80\n",
      "0.8153869047619048\n",
      "\n",
      "Iteration:  90\n",
      "0.8209226190476191\n",
      "\n",
      "Iteration:  100\n",
      "0.840922619047619\n",
      "\n",
      "Iteration:  110\n",
      "0.8430952380952381\n",
      "\n",
      "Iteration:  120\n",
      "0.845922619047619\n",
      "\n",
      "Iteration:  130\n",
      "0.8580654761904762\n",
      "\n",
      "Iteration:  140\n",
      "0.861547619047619\n",
      "\n",
      "Iteration:  150\n",
      "0.8606845238095238\n",
      "\n",
      "Iteration:  160\n",
      "0.8591071428571428\n",
      "\n",
      "Iteration:  170\n",
      "0.8682738095238095\n",
      "\n",
      "Iteration:  180\n",
      "0.8825595238095238\n",
      "\n",
      "Iteration:  190\n",
      "0.8850892857142857\n",
      "\n",
      "Iteration:  200\n",
      "0.8809821428571428\n",
      "\n",
      "Iteration:  210\n",
      "0.8768452380952381\n",
      "\n",
      "Iteration:  220\n",
      "0.8910714285714286\n",
      "\n",
      "Iteration:  230\n",
      "0.8936309523809524\n",
      "\n",
      "Iteration:  240\n",
      "0.8946726190476191\n",
      "\n",
      "Iteration:  250\n",
      "0.8926785714285714\n",
      "\n",
      "Iteration:  260\n",
      "0.878095238095238\n",
      "\n",
      "Iteration:  270\n",
      "0.8985714285714286\n",
      "\n",
      "Iteration:  280\n",
      "0.9000892857142857\n",
      "\n",
      "Iteration:  290\n",
      "0.9018452380952381\n",
      "\n",
      "Iteration:  300\n",
      "0.9028273809523809\n",
      "\n",
      "Iteration:  310\n",
      "0.9038988095238095\n",
      "\n",
      "Iteration:  320\n",
      "0.9036904761904762\n",
      "\n",
      "Iteration:  330\n",
      "0.8935714285714286\n",
      "\n",
      "Iteration:  340\n",
      "0.902797619047619\n",
      "\n",
      "Iteration:  350\n",
      "0.9072916666666667\n",
      "\n",
      "Iteration:  360\n",
      "0.9084523809523809\n",
      "\n",
      "Iteration:  370\n",
      "0.909345238095238\n",
      "\n",
      "Iteration:  380\n",
      "0.9099404761904762\n",
      "\n",
      "Iteration:  390\n",
      "0.910625\n",
      "\n",
      "Iteration:  400\n",
      "0.9111309523809524\n",
      "\n",
      "Iteration:  410\n",
      "0.9120238095238096\n",
      "\n",
      "Iteration:  420\n",
      "0.9125\n",
      "\n",
      "Iteration:  430\n",
      "0.9114880952380953\n",
      "\n",
      "Iteration:  440\n",
      "0.9053869047619048\n",
      "\n",
      "Iteration:  450\n",
      "0.9086011904761905\n",
      "\n",
      "Iteration:  460\n",
      "0.9146726190476191\n",
      "\n",
      "Iteration:  470\n",
      "0.9152976190476191\n",
      "\n",
      "Iteration:  480\n",
      "0.9157738095238095\n",
      "\n",
      "Iteration:  490\n",
      "0.916547619047619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = Neural_Network(train_data, train_labels)\n",
    "\n",
    "x.train(0.5, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  3\n",
      "Prediction:  3\n",
      "Confidence:  93.81255080796734\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Takes 1 random record and Tests\n",
    "x.predict(test_data, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
